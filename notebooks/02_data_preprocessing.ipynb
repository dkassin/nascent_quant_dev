{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "## Introduction\n",
    "This notebook focuses on loading the raw data, performing initial data cleaning, eventually creating a processed_data csv.\n",
    "\n",
    "### Folder Structure & File Handling\n",
    "To make this process replicable, create two folders in the `data` directory: one titled `raw` and the other titled `processed`.\n",
    "The initial function loads the data from the `raw` data folder. This file is kept in the `.gitignore` to prevent it from being tracked in version control. The file paths in this script and the rest of the notebooks should then work seamlessly.\n",
    "The file paths in this script and the rest of the notebooks should then work. \n",
    "\n",
    "### Data Cleaning \n",
    "This initial script checks for null values in both of the raw columns provided: `signal` and `equity_curve`. To determine the success of the signals, a third column, `equity_return`, is created at this stage. It represents the percentage return of the next day's equity value compared to the current day's.\n",
    "\n",
    "### Avoiding Look-Ahead Bias\n",
    "We are aware of look-ahead bias, but also equally aware that the equity returns column will be necessary for calculating or trading statistics in a simple and easy to repeat manner. As such any model, or testing strategy will not use or have accesses to the equity returns for any decision making process.\n",
    "\n",
    "### Removing Incomplete Records\n",
    "The script also removes the final record in the data, as it will not have a corresponding next day's equity value for comparison.\n",
    "\n",
    "### Saving Processed Data\n",
    "The final part of this script saves the preprocessed data to a CSV file in the `data/processed/` folder for other notebooks to ingest and use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    data['signal'] = pd.to_numeric(data['signal'], errors='coerce')\n",
    "    data['equity_curve'] = pd.to_numeric(data['equity_curve'], errors='coerce')\n",
    "\n",
    "    null_signals = data['signal'].isna().sum()\n",
    "    null_equity_curve = data['equity_curve'].isna().sum()\n",
    "\n",
    "    print(f\"Number of null values in 'signal': {null_signals}\")\n",
    "    print(f\"Number of null values in 'equity_curve': {null_equity_curve}\")\n",
    "\n",
    "    data = data.dropna()\n",
    "\n",
    "    data['equity_returns'] = data['equity_curve'].pct_change().shift(-1)\n",
    "\n",
    "    data = data.dropna()\n",
    "    data = data[:-1]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/raw/sovereign_quant_developer_assignment_data.csv\"\n",
    "data = load_and_preprocess_data(file_path)\n",
    "\n",
    "processed_file_path = \"../data/processed/processed_data.csv\"\n",
    "data.to_csv(processed_file_path, index = False)\n",
    "\n",
    "data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
